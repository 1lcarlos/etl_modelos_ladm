# src/logger.py
"""
Sistema de logging personalizado para el ETL
Genera logs detallados con timestamps y informaciÃ³n por esquema
"""

import logging
import os
from datetime import datetime
from typing import Optional

class ETLLogger:
    """
    Clase para manejar el logging del ETL de manera centralizada.
    Crea archivos de log con timestamp y maneja logs por esquema.
    """
    
    def __init__(self, log_directory: str = './logs/'):
        """
        Inicializa el sistema de logging
        
        Args:
            log_directory: Directorio donde se guardarÃ¡n los logs
        """
        self.log_directory = log_directory
        self.ensure_log_directory()
        
        # Generar nombre de archivo con timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_filename = f"etl_execution_{timestamp}.txt"
        self.log_filepath = os.path.join(log_directory, self.log_filename)
        
        # Configurar logging
        self.setup_logging()
        self.logger = logging.getLogger('ETL')
        
        # EstadÃ­sticas del proceso
        self.stats = {
            'start_time': datetime.now(),
            'schemas_processed': 0,
            'schemas_failed': 0,
            'total_queries': 0,
            'total_inserts': 0,
            'total_records': 0
        }
        
        self.log_process_start()
    
    def ensure_log_directory(self):
        """
        Crea el directorio de logs si no existe
        """
        if not os.path.exists(self.log_directory):
            os.makedirs(self.log_directory)
    
    def setup_logging(self):
        """
        Configura el sistema de logging para escribir tanto en archivo como en consola
        """
        # Limpiar handlers existentes
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)
        
        # Configurar formato
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # Handler para archivo
        file_handler = logging.FileHandler(self.log_filepath, encoding='utf-8')
        file_handler.setFormatter(formatter)
        file_handler.setLevel(logging.INFO)
        
        # Handler para consola
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(logging.INFO)
        
        # Configurar logger principal
        logger = logging.getLogger('ETL')
        logger.setLevel(logging.INFO)
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        # Evitar duplicaciÃ³n de logs
        logger.propagate = False
    
    def log_process_start(self):
        """
        Registra el inicio del proceso ETL
        """
        self.logger.info("=" * 80)
        self.logger.info("ðŸš€ INICIANDO PROCESO ETL POSTGRESQL")
        self.logger.info("=" * 80)
        self.logger.info(f"ðŸ“ Archivo de log: {self.log_filename}")
        self.logger.info(f"ðŸ• Fecha y hora de inicio: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    def log_schema_start(self, schema: str):
        """
        Registra el inicio del procesamiento de un esquema
        
        Args:
            schema: Nombre del esquema que se va a procesar
        """
        self.logger.info("-" * 60)
        self.logger.info(f"ðŸ“‹ PROCESANDO ESQUEMA: {schema}")
        self.logger.info("-" * 60)
    
    def log_schema_success(self, schema: str, queries_count: int, inserts_count: int, records_count: int):
        """
        Registra el Ã©xito en el procesamiento de un esquema
        
        Args:
            schema: Nombre del esquema procesado
            queries_count: NÃºmero de queries ejecutadas
            inserts_count: NÃºmero de inserts ejecutados
            records_count: NÃºmero de registros procesados
        """
        self.stats['schemas_processed'] += 1
        self.stats['total_queries'] += queries_count
        self.stats['total_inserts'] += inserts_count
        self.stats['total_records'] += records_count
        
        self.logger.info(f"âœ… ESQUEMA {schema} PROCESADO EXITOSAMENTE")
        self.logger.info(f"   ðŸ“Š Queries ejecutadas: {queries_count}")
        self.logger.info(f"   ðŸ“Š Inserts ejecutados: {inserts_count}")
        self.logger.info(f"   ðŸ“Š Registros procesados: {records_count}")
    
    def log_schema_error(self, schema: str, error: Exception, step: str):
        """
        Registra un error en el procesamiento de un esquema
        
        Args:
            schema: Nombre del esquema que fallÃ³
            error: ExcepciÃ³n ocurrida
            step: Paso del proceso donde ocurriÃ³ el error
        """
        self.stats['schemas_failed'] += 1
        
        self.logger.error(f"âŒ ERROR EN ESQUEMA {schema}")
        self.logger.error(f"   ðŸ” Paso: {step}")
        self.logger.error(f"   ðŸ’¥ Error: {str(error)}")
        self.logger.error(f"   ðŸ“ Tipo de error: {type(error).__name__}")
    
    def log_query_execution(self, filename: str, schema: str, rows_affected: int):
        """
        Registra la ejecuciÃ³n de una query
        
        Args:
            filename: Nombre del archivo SQL ejecutado
            schema: Esquema donde se ejecutÃ³
            rows_affected: NÃºmero de filas afectadas
        """
        self.logger.info(f"ðŸ” Query ejecutada: {filename} en esquema {schema} - {rows_affected} filas")
    
    def log_insert_execution(self, filename: str, rows_affected: int):
        """
        Registra la ejecuciÃ³n de un insert
        
        Args:
            filename: Nombre del archivo SQL ejecutado
            rows_affected: NÃºmero de filas insertadas
        """
        self.logger.info(f"ðŸ“¥ Insert ejecutado: {filename} - {rows_affected} filas insertadas")
    
    def log_temp_table_operation(self, operation: str, table_name: str, success: bool):
        """
        Registra operaciones en tablas temporales
        
        Args:
            operation: Tipo de operaciÃ³n (CREATE/DROP)
            table_name: Nombre de la tabla
            success: Si la operaciÃ³n fue exitosa
        """
        status = "âœ…" if success else "âŒ"
        self.logger.info(f"{status} Tabla temporal {operation}: {table_name}")
    
    def log_process_end(self):
        """
        Registra el final del proceso ETL con estadÃ­sticas
        """
        end_time = datetime.now()
        duration = end_time - self.stats['start_time']
        
        self.logger.info("=" * 80)
        self.logger.info("ðŸ PROCESO ETL FINALIZADO")
        self.logger.info("=" * 80)
        self.logger.info(f"ðŸ• Hora de finalizaciÃ³n: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"â±ï¸ DuraciÃ³n total: {duration}")
        self.logger.info(f"ðŸ“ˆ ESTADÃSTICAS FINALES:")
        self.logger.info(f"   ðŸ”¢ Esquemas procesados exitosamente: {self.stats['schemas_processed']}")
        self.logger.info(f"   âŒ Esquemas con errores: {self.stats['schemas_failed']}")
        self.logger.info(f"   ðŸ” Total de queries ejecutadas: {self.stats['total_queries']}")
        self.logger.info(f"   ðŸ“¥ Total de inserts ejecutados: {self.stats['total_inserts']}")
        self.logger.info(f"   ðŸ“Š Total de registros procesados: {self.stats['total_records']}")
        
        if self.stats['schemas_failed'] == 0:
            self.logger.info("ðŸŽ‰ PROCESO COMPLETADO SIN ERRORES")
        else:
            self.logger.warning(f"âš ï¸ PROCESO COMPLETADO CON {self.stats['schemas_failed']} ESQUEMAS CON ERRORES")
    
    def get_log_filepath(self) -> str:
        """
        Retorna la ruta completa del archivo de log
        
        Returns:
            str: Ruta del archivo de log
        """
        return self.log_filepath